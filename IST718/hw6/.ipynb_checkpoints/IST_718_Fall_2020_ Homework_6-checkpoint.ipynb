{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "4e6cefb0049d48a2f4648d752841bb06",
     "grade": false,
     "grade_id": "cell-b038e38b5e3072a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Prepared by: Prof Daniel E Acuna deacuna@syr.edu\n",
    "- Modified by: Prof Humayun Khan <hhkhan@syr.edu>\n",
    "- Faculty Assistant: Rashika Pramod Singh <rsingh37@syr.edu>\n",
    "- Faculty Assistant: Rohan Nitin Mahajan <rmahaj01@syr.edu>\n",
    "\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- __In general use Spark, Spark machine learning, Spark data frames, RDD's, and map reduce to solve all problems unless instructed otherwise.__\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers from your classmates.  Short code snippets from the internet are allowed.  Code from the class text books or class provided code can be copied in its entirety.__\n",
    "- There could be tests in some cells (i.e., `assert` and `np.testing` statements). These tests (if present) are used to grade your answers. **However, the professor and FAs could use __additional__ tests for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- Grading feedback cells are there for graders to provide feedback to students.  Do not change or remove grading feedback cells.\n",
    "- Do not add or remove files from your Git repo. Do not change file names either. This also means **do not change the title** of the ipython notebook.\n",
    "- You are free to add additional code cells around the cells marked `your code here`. You may use toPandas() to print the head of data frames. Plots should include a title, and axis labels.  Unless otherwise stated, plots may be made using your favorite Python package(s).\n",
    "- Code is included to read files from Databricks or from local filesystem depending on environment. It is assumed you know how to upload data files in Databricks as needed. If done right, the same code will run in either environment.\n",
    "- There are usually many coding solutions to a problem. As a thumb rule, write code that is easy to read. You may assume your readers are programmers. Use comments sparingly and where necesessary. Comments reveal intent. So, even when code is a little off target, effort will be recognized and rewarded. But runtime errors will be penalized.\n",
    "- Before downloading and submitting your work through Github Classroom, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- **Good luck!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load these packages\n",
    "import pyspark\n",
    "from pyspark.ml import feature, classification\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as fn\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import feature, regression, evaluation, Pipeline\n",
    "from pyspark.sql import functions as fn, Row\n",
    "import matplotlib.pyplot as plt\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "a_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to determine if we are running on data bricks\n",
    "# Return true if running in the data bricks environment, false otherwise\n",
    "import os\n",
    "def is_databricks():\n",
    "    if os.getenv(\"DATABRICKS_RUNTIME_VERSION\") != None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Define a function to read the data. The full path name is constructed by checking\n",
    "# the runtime environment to determine if it is databricks or a personal computer.\n",
    "# On the local filesystem the data is assumed to be in the same directory as the code.\n",
    "# On databricks, the data path is assumed to be at '/FileStore/tables/' location.\n",
    "# \n",
    "# Parameter(s):\n",
    "#   name: The base name of the file, parquet file or parquet directory\n",
    "# Return Value:\n",
    "#   full_path_name: the full path name of the data based on the runtime environment\n",
    "#\n",
    "# Correct Usage Example (pass ONLY the full file name):\n",
    "#   name_to_load = get_datapath(\"sms_spam.csv\") # correct  \n",
    "#   \n",
    "# Incorrect Usage Examples:\n",
    "#   name_to_load = get_datapath(\"/sms_spam.csv\") # incorrect\n",
    "#   name_to_load = get_datapath(\"sms_spam.csv/\") # incorrect\n",
    "#   name_to_load = get_datapath(\"c:/users/will/data/sms_spam.csv\") incorrect\n",
    "#\n",
    "def get_datapath(name):    \n",
    "    if is_databricks():\n",
    "        full_path_name = \"/FileStore/tables/%s\" % name\n",
    "    else:\n",
    "        full_path_name = name\n",
    "    return full_path_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Random Forest and gradient boosted trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these questions, we will examine the famous [Auto dataset](https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Auto.html). With this dataset, the goal is to predict the miles per gallon (`mpg`) performance based on characteristics of the car such as number of cylinders (`cylinders`), displacement between wheels (`displacement`), horsepower of the engine (`horsepower`), weight of the car (`weight`), top acceleration (`acceleration`), year of the model (`year`), and origin (`origin`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "checksum": "d835a01d8146fbfa5aed060dae16d9fb",
     "grade": false,
     "grade_id": "cell-219523fd6f45f014",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mpg: double (nullable = true)\n",
      " |-- cylinders: integer (nullable = true)\n",
      " |-- displacement: double (nullable = true)\n",
      " |-- weight: integer (nullable = true)\n",
      " |-- acceleration: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- origin: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- horsepower: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "mpg_df = spark.read.csv(get_datapath('Auto.csv'), header=True, inferSchema=True).\\\n",
    "    drop('_c0').\\\n",
    "    withColumn('horsepower2', fn.col('horsepower').cast('int')).\\\n",
    "    drop('horsepower').\\\n",
    "    withColumnRenamed('horsepower2', 'horsepower').\\\n",
    "    dropna()\n",
    "training_df, validation_df, testing_df = mpg_df.randomSplit([0.6, 0.3, 0.1], seed=0)\n",
    "mpg_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: (20 pts)\n",
    "\n",
    "Create three pipelines that contain three different random forests that take in all features from `mpg_df` (`cylinders`, `displacement`, `horsepower`, `weight`, `acceleration`, `year`, and `origin`) to predict (`mpg`). **Set the `seed` parameter of the random forest to 0.** Fit these pipelines to the training data (`training_df`):\n",
    "\n",
    "- `pipe_rf1`: Random forest with `maxDepth=1` and `numTrees=60`\n",
    "- `pipe_rf2`: Random forest with `maxDepth=3` and `numTrees=40`\n",
    "- `pipe_rf3`: Random forest with `maxDepth=6`, `numTrees=20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "2912f0aa0562283b8c2b9b8d330a9e8c",
     "grade": false,
     "grade_id": "cell-5d34f31b40350198",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "inputs = list(training_df.columns[1:])\n",
    "inputs.remove('name')\n",
    "va = feature.VectorAssembler().setInputCols(inputs).setOutputCol('features') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "ab0fe44d4fffc964b8d76f2d7cc0bc52",
     "grade": true,
     "grade_id": "cell-896bdef9bf893231",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "np.testing.assert_equal(type(pipe_rf1.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_rf2.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_rf3.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(pipe_rf1.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(pipe_rf2.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(pipe_rf3.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(pipe_rf1.transform(training_df)), pyspark.sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(type(pipe_rf2.transform(training_df)), pyspark.sql.dataframe.DataFrame)\n",
    "np.testing.assert_equal(type(pipe_rf3.transform(training_df)), pyspark.sql.dataframe.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 (20 pts)\n",
    "\n",
    "Use the following evaluator to compute the $R^2$ of the models on validation data. Assign the $R^2$ of the three models to `R2_1`, `R2_2`, and `R2_3`, respectively, and the performance. Assign the best pipeline based on validation performance to a variable `best_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = evaluation.RegressionEvaluator(labelCol='mpg', metricName='r2')\n",
    "# use it as follows:\n",
    "#   evaluator.evaluate(fitted_pipeline.transform(df)) -> R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "05aa55bb93c8241e41bb5608503701cc",
     "grade": false,
     "grade_id": "cell-91cd57be67b86f2a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "f54b5ffaa1b173049912fcc6e5153295",
     "grade": true,
     "grade_id": "cell-5399ae6afb414351",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "np.testing.assert_equal(type(best_model.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(best_model.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(best_model.transform(validation_df)), pyspark.sql.dataframe.DataFrame)\n",
    "np.testing.assert_array_less(R2_1, 1.)\n",
    "np.testing.assert_array_less(0.5, R2_1)\n",
    "np.testing.assert_array_less(R2_2, 1.)\n",
    "np.testing.assert_array_less(0.5, R2_2)\n",
    "np.testing.assert_array_less(R2_3, 1.)\n",
    "np.testing.assert_array_less(0.5, R2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: 10 pts\n",
    "\n",
    "Compute the $R^2$ of the model on testing data, print it, and assign it to variable `R2_best`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "d024cc767cf9091d250f11c6c26fc729",
     "grade": false,
     "grade_id": "cell-86f5f0eaa917209f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create AUC_best below\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "be06b9c3fd35043998cada2e4c82af63",
     "grade": true,
     "grade_id": "cell-bd2f7d28b44ac691",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "np.testing.assert_array_less(R2_best, 1.)\n",
    "np.testing.assert_array_less(0.5, R2_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: 10 pts\n",
    "\n",
    "Using the parameters of the best model, create a new pipeline called `final_model` and fit it to the entire data (`mpg_df`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "f1e9753be63f387d37db812d4102e26c",
     "grade": false,
     "grade_id": "cell-2574a5ca8f12ce94",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create the fitted pipeline `final_model` here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "10209c86da7aca0f6d99708efb051f44",
     "grade": true,
     "grade_id": "cell-bcce92747a0d2ba5",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "np.testing.assert_equal(type(final_model.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(final_model.stages[1]), regression.RandomForestRegressionModel)\n",
    "np.testing.assert_equal(type(final_model.transform(mpg_df)), pyspark.sql.dataframe.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5: 10 pts\n",
    "\n",
    "Create a pandas dataframe `feature_importance` with the columns `feature` and `importance` which contains the names of the features (`cylinder`, `displacement`, etc.) and their feature importances as determined by the random forest of the final model. Sort the dataframe by `importance` in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "89dc0c52dff983147af006f48049dd3e",
     "grade": false,
     "grade_id": "cell-5b666b921af5a375",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create feature_importance below\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display it here\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "a174ad97cc20a8fe9385ded1a56597f7",
     "grade": true,
     "grade_id": "cell-de7873ad0b54f277",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "assert type(feature_importance) == pd.core.frame.DataFrame\n",
    "np.testing.assert_array_equal(list(feature_importance.columns), ['feature', 'importance'])\n",
    "np.testing.assert_array_equal(list(feature_importance.columns), ['feature', 'importance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment below on the importance that random forest has given to each feature. Are they reasonable? Do they tell you anything valuable about the mpg dataset? Answer in the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "b2c41f651112504fa5bc52db64459564",
     "grade": true,
     "grade_id": "cell-cd1eb09a9ba5aaa9",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify\n",
    "end = time.time()\n",
    "print(\"Part1 took %0.2f seconds\"%(end - a_start))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6:  10 pts.\n",
    "\n",
    "Pick any of the trees from the final model and assign its `toDebugString` property to a variable `example_tree`. Print this variable and add comments to the cell describing how you think this particular tree is fitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "b212587e3d2f28ad35f04e2a6149e762",
     "grade": false,
     "grade_id": "cell-7476baa7ceb72c05",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create a variable example_tree with the toDebugString property of a tree from final_model.\n",
    "# print this string and comment in this same cell about the branches that this tree fit\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "9f35c194d03338e1a9e24d771fb28c2e",
     "grade": true,
     "grade_id": "cell-80c89e10a60f6ce2",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "assert type(example_tree) == str\n",
    "assert 'DecisionTreeRegressionModel' in example_tree\n",
    "assert 'feature 0' in example_tree\n",
    "assert 'If' in example_tree\n",
    "assert 'Else' in example_tree\n",
    "assert 'Predict' in example_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Question 7 (20 pts)**\n",
    "\n",
    "Gradient boosted trees are becoming increasingly popular for competitions. There is a high-performance implementation, [xgboost](https://en.wikipedia.org/wiki/XGBoost), that is particularly popular. Compare gradient boosted regression to the best model found with random forest in Question 3. Use the validation set. For GBR, use all the default parameters except make `seed=0`. Assign the pipeline and the $R^2$ of the model to `gbr_pipe` and `R2_gbr`, respectively. Does it have an amazing or dissapointing $R^2$? Comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "d399ce658c943b8f572a428367c1725e",
     "grade": false,
     "grade_id": "cell-edab7ea019e8b267",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your models here\n",
    "print(\"Performance of best RF: \", evaluator.evaluate(best_model.transform(validation_df)))\n",
    "print(\"Performance of GBR: \", R2_gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "checksum": "7636ddf552f508aaa5952350f9b0a210",
     "grade": true,
     "grade_id": "cell-f7b1ed961851c406",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# tests\n",
    "np.testing.assert_equal(type(gbr_pipe.stages[0]), feature.VectorAssembler)\n",
    "np.testing.assert_equal(type(gbr_pipe.stages[1]), regression.GBTRegressionModel)\n",
    "np.testing.assert_equal(type(gbr_pipe.transform(validation_df)), pyspark.sql.dataframe.DataFrame)\n",
    "np.testing.assert_array_less(R2_gbr, 1.)\n",
    "np.testing.assert_array_less(0.5, R2_gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify\n",
    "end = time.time()\n",
    "print(\"Part2 took %0.2f seconds\"%(end - a_start))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*END OF CODE*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
